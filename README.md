# ğŸš€ Pipeline de Machine Learning Temps RÃ©el â€“ Architecture Kappa

## ğŸ“‘ Table des MatiÃ¨res
1. Description du Projet  
2. Architecture du Projet  
3. Guide dâ€™Installation  
   - PrÃ©-requis  
   - Clonage du Projet  
   - DÃ©marrage des Conteneurs  
4. Lancement du Pipeline  
   - API de Streaming  
   - Producteur Kafka  
   - Consommateur Spark  
   - Visualisation du RMSE  
   - PrÃ©dictions en Temps RÃ©el  
5. Technologies UtilisÃ©es  
6. Structure du Projet  
7. RÃ©sultats et KPI  

---

## 1. Description du Projet

Ce projet implÃ©mente un **pipeline de Machine Learning en temps rÃ©el** basÃ© sur lâ€™**architecture Kappa**.  
Il permet de traiter un flux continu de donnÃ©es liÃ©es aux Ã©missions de COâ‚‚ des vÃ©hicules et dâ€™effectuer :

- La diffusion de donnÃ©es depuis un fichier CSV via une API
- Le streaming des donnÃ©es avec Apache Kafka
- Lâ€™entraÃ®nement incrÃ©mental dâ€™un modÃ¨le de Machine Learning avec Apache Spark
- Le suivi en temps rÃ©el des performances du modÃ¨le
- La prÃ©diction interactive des Ã©missions de COâ‚‚

Lâ€™ensemble du systÃ¨me est **entiÃ¨rement containerisÃ©** et orchestrÃ© avec **Docker Compose**.

---

## 2. Architecture du Projet

Le projet suit une **architecture Kappa**, dans laquelle une seule chaÃ®ne de traitement streaming est utilisÃ©e pour :

- Les donnÃ©es historiques
- Les donnÃ©es temps rÃ©el

### Composants principaux :

- **FastAPI** : API de streaming des donnÃ©es CSV
- **Apache Kafka** : transport des messages en temps rÃ©el
- **Zookeeper** : coordination de Kafka
- **Apache Spark Structured Streaming** : traitement et entraÃ®nement du modÃ¨le
- **Scikit-learn** : modÃ¨le de rÃ©gression incrÃ©mental (SGDRegressor)
- **Streamlit** : visualisation et interface utilisateur

---

## 3. Guide dâ€™Installation

### 3.1 PrÃ©-requis

- Docker Desktop installÃ©
- Docker Compose disponible
- Au moins 8 Go de RAM recommandÃ©s

VÃ©rification :

```bash
- docker --version
- docker-compose --version
### 3.2 DÃ©marrage des Conteneurs

Lancer tous les services avec Docker Compose :

```bash
docker-compose up -d

- Les services suivants sont dÃ©marrÃ©s automatiquement :

- Zookeeper

- Kafka

- API de streaming

- Producteur Kafka

- Consommateur Spark

- Interface Streamlit

## 4.Lancement du Pipeline
### 4.1 API de Streaming

Endpoint exposÃ© :

GET http://localhost:8000/stream


Fonctionnement :

Lecture du fichier CSV

Diffusion des donnÃ©es ligne par ligne en continu

### 4.2 Producteur Kafka

RÃ´le du producteur :

Consommer le flux HTTP depuis lâ€™API

Publier les messages dans Kafka

Configuration principale :

Broker : kafka:9092
Topic  : streaming_data


Surveillance :

docker logs kafka-producer -f

### 4.3 Consommateur Spark

FonctionnalitÃ©s :

Lecture des donnÃ©es depuis Kafka

Application dâ€™un schÃ©ma structurÃ©

EntraÃ®nement incrÃ©mental du modÃ¨le (SGDRegressor)

Calcul du RMSE par batch

Sauvegarde du modÃ¨le et des mÃ©triques

Surveillance :

docker logs spark-consumer -f

### 4.4 Visualisation du RMSE

AccÃ¨s Ã  Streamlit :

http://localhost:8501


FonctionnalitÃ©s :

Graphe dâ€™Ã©volution du RMSE par batch

KPI : dernier RMSE

RafraÃ®chissement automatique toutes les 5 secondes

### 4.5 PrÃ©dictions en Temps RÃ©el

FonctionnalitÃ©s de la page PrÃ©diction :

Saisie des caractÃ©ristiques du vÃ©hicule

PrÃ©diction instantanÃ©e des Ã©missions de COâ‚‚

Rechargement dynamique du modÃ¨le entraÃ®nÃ©

## 5. Technologies UtilisÃ©es
API               : FastAPI
Streaming         : Apache Kafka
Coordination      : Zookeeper
Traitement        : Apache Spark
Machine Learning  : Scikit-learn
Visualisation     : Streamlit
Conteneurisation  : Docker
Orchestration     : Docker Compose

## 6. Structure du Projet
ml-pipeline-spark-kafka/
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ producer/
â”‚   â””â”€â”€ producer.py
â”‚
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ consumer.py
â”‚
â”œâ”€â”€ streamlit/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ pages/
â”‚       â””â”€â”€ prediction.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ co2_processed.csv
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ sgd.joblib
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md

## 7. RÃ©sultats et KPI
- EntraÃ®nement incrÃ©mental du modÃ¨le en streaming
- RMSE calculÃ© et mis Ã  jour Ã  chaque batch
- Visualisation temps rÃ©el des performances
- PrÃ©dictions interactives via interface web